{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6: \n",
    "\n",
    "**DUE:** 5pm EST, April 9, 2020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Conceptual:** Short answer questions. Be concise\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Let us consider the \"curse of dimensionality\" (i.e., when the ratio of predictor variables, p, to observations, n, is high) in the context of kNN. Answer the following:\n",
    "\n",
    "<br>\n",
    "\n",
    "(a) Suppose that we have a set of observations, each with measurements on p = 1 feature, X. We assume that X is uniformly (evenly) distributed between 0 and 1. Associated with each observation is a response value. Suppose that we wish to predict a test observation’s response using only observations that are within 10% of the range of X closest to that test observation. For instance, in order to predict the response for a test observation with X = 0.6, we will use observations in the range [0.55,0.65]. On average, what fraction of the available observations will we use to make the prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "Because X is uniformly distributed, on average 1/10 (or 10%) of the available observations will be used to make the prediction. However, once you start hitting x<.05 and x>.95, since X only ranges from 0 to 1, the number of observations within 10% of X starts to be less than 10% of the observations present (i.e., if x= .02 then your range includes [-.03, .07]. Since there are no observations for x<0, KNN would only use the values from [0,.07]. So in reality, I imagine on average you use slightly less than 10%.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Suppose that we have a set of observations, each with measurements on p = 2 features, X1 and X2. We assume that (X1,X2) are uniformly distributed between 0 and 1. We wish to predict a test observation’s response using only observations that are within 10% of the range of X1 and within 10% of the range of X2 closest to that test observation. For instance, in order to predict the response for a test observation with X1 = 0.6 and X2 = 0.35, we will use observations in the range [0.55, 0.65] for X1 and in the range [0.3, 0.4] for X2. On average, what fraction of the available observations will we use to make the prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "In this case, on average we would use (1/10) * (1/10) = 1/100 or 1% percent of observations. However, following the same reasoning I noted above for the ends of the distribution of X, i imagine in reality, on average, you use slightly less than 1%. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Now suppose that we have a set of observations on p = 100 features. Again the observations are uniformly distributed on each feature, and again each feature ranges in value from 0 to 1. We wish to predict a test observation’s response using observations within the 10% of each feature’s range that is closest to that test observation. What fraction of the available observations will we use to make the prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "Following the same pattern from a) and b) above, on average, we would use slightly less than:\n",
    "\n",
    "$ (0.1^{100} * 100) = 1 x 10^{-98}$ % of observations...which is a really small number. And why KNN requires a large N.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c)  Using your answers to parts (a)–(c), argue that a drawback of KNN when p is large is that there are very few training observations “near” any given test observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "As you increase p, the probability of having \"neighbors\" close by gets increasingly smaller. To think about it simply, with more features you take on more undelrying distributions in your sample, or rather, \"neiborhoods\". The more neighborhoods you have, the more the city grows, and the harder it gets to find neighbors, or friends like you. Or rather, the the city gets bigger, which results in lower odds/probability of a neighborly encounter. You would need to make up for it by edding a lot more buddies to your neighborhood to increase your odds/probability. \n",
    "\n",
    "With KNN as as p increases, you need exponentially more power (subjects) to compensate for the increase in dimensionality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "2. Explain how k-fold cross-validation is implemented. What are the advantages and disadvantages of k-fold cross-validation relative to LOOCV?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "k-fold cross-validation is implemented by taking a set of a particular number of observations and randomly splitting into k non-overlapping groups, or folds so as to produce a testing and training set each time that do not insect and can be used to validate.\n",
    "\n",
    "K-fold essnetially more blinded in the way its implemented, so you have more bias in your model. LOOCV is kind of the opposite, less blunt tool more a sharp knife. So, in constant, you run the risk higher variance. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "3. Differentiate the bootstrap from a permutation test. Describe each and when is it appropriate to each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "\n",
    "Permutation = sampling without replacement. \n",
    "\n",
    "\n",
    "Bootstrap = sampling with replacement. \n",
    "\n",
    "Bootstrapping is employed when you have uncertainty about a particular statistic, but not your hypothesis. Whereas permutation is employed when you have uncertainty regarding your hypotehses and you essentially need to break you sample and relationship under examination down to have a reference point for considering,\"what does it look like if this effect doesn't exist?\". Which is the null hypohesis (most times). However, with permutation you are peruting the distributon for your null, so you need to be thoughtful about that is (it may be something different than exist or not exist, so to speak). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Applied:** Show your code & plots\n",
    "\n",
    "We will use both datasets from the HCP dataset for these problems. Include conceptual answers to questions as comments in code cells. You should use the tidyverse and class libraries for this assignment, as well as the data table for the HCP data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Use kNN to build a classifier that for predicting Gender using the unadjusted Flanker task performance (Flanker_unadj). \n",
    "\n",
    "(a) Split the data set up into 1006 training observations and 200 test observations. Clasffiy using kNN with k = 5. Show your classification accuracy as a predicted vs. observed table, and report the mean classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/pn/0ydxg3g97q9_9g179fhkgt6c0000gr/T//RtmpwleM5L/downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsed with column specification:\n",
      "cols(\n",
      "  .default = col_double(),\n",
      "  Release = \u001b[31mcol_character()\u001b[39m,\n",
      "  Acquisition = \u001b[31mcol_character()\u001b[39m,\n",
      "  Gender = \u001b[31mcol_character()\u001b[39m,\n",
      "  Age = \u001b[31mcol_character()\u001b[39m,\n",
      "  PSQI_BedTime = \u001b[34mcol_time(format = \"\")\u001b[39m,\n",
      "  PSQI_GetUpTime = \u001b[34mcol_time(format = \"\")\u001b[39m,\n",
      "  NEORAW_01 = \u001b[31mcol_character()\u001b[39m,\n",
      "  NEORAW_02 = \u001b[31mcol_character()\u001b[39m,\n",
      "  NEORAW_03 = \u001b[31mcol_character()\u001b[39m,\n",
      "  NEORAW_04 = \u001b[31mcol_character()\u001b[39m,\n",
      "  NEORAW_05 = \u001b[31mcol_character()\u001b[39m,\n",
      "  NEORAW_06 = \u001b[31mcol_character()\u001b[39m,\n",
      "  NEORAW_07 = \u001b[31mcol_character()\u001b[39m,\n",
      "  NEORAW_08 = \u001b[31mcol_character()\u001b[39m,\n",
      "  NEORAW_09 = \u001b[31mcol_character()\u001b[39m,\n",
      "  NEORAW_10 = \u001b[31mcol_character()\u001b[39m,\n",
      "  NEORAW_11 = \u001b[31mcol_character()\u001b[39m,\n",
      "  NEORAW_12 = \u001b[31mcol_character()\u001b[39m,\n",
      "  NEORAW_13 = \u001b[31mcol_character()\u001b[39m,\n",
      "  NEORAW_14 = \u001b[31mcol_character()\u001b[39m\n",
      "  # ... with 46 more columns\n",
      ")\n",
      "\n",
      "See spec(...) for full column specifications.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A tibble: 6 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Subject</th><th scope=col>Gender</th><th scope=col>Flanker_Unadj</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>100004</td><td>M</td><td>121.97</td></tr>\n",
       "\t<tr><td>100206</td><td>M</td><td>130.42</td></tr>\n",
       "\t<tr><td>100307</td><td>F</td><td>112.56</td></tr>\n",
       "\t<tr><td>100408</td><td>M</td><td>121.18</td></tr>\n",
       "\t<tr><td>100610</td><td>M</td><td>126.53</td></tr>\n",
       "\t<tr><td>101006</td><td>F</td><td>101.85</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 3\n",
       "\\begin{tabular}{lll}\n",
       " Subject & Gender & Flanker\\_Unadj\\\\\n",
       " <dbl> & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 100004 & M & 121.97\\\\\n",
       "\t 100206 & M & 130.42\\\\\n",
       "\t 100307 & F & 112.56\\\\\n",
       "\t 100408 & M & 121.18\\\\\n",
       "\t 100610 & M & 126.53\\\\\n",
       "\t 101006 & F & 101.85\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 3\n",
       "\n",
       "| Subject &lt;dbl&gt; | Gender &lt;chr&gt; | Flanker_Unadj &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 100004 | M | 121.97 |\n",
       "| 100206 | M | 130.42 |\n",
       "| 100307 | F | 112.56 |\n",
       "| 100408 | M | 121.18 |\n",
       "| 100610 | M | 126.53 |\n",
       "| 101006 | F | 101.85 |\n",
       "\n"
      ],
      "text/plain": [
       "  Subject Gender Flanker_Unadj\n",
       "1 100004  M      121.97       \n",
       "2 100206  M      130.42       \n",
       "3 100307  F      112.56       \n",
       "4 100408  M      121.18       \n",
       "5 100610  M      126.53       \n",
       "6 101006  F      101.85       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ERROR",
     "evalue": "Error in knn(train.x, test.x, train.y, k = 5): 'train' and 'class' have different lengths\n",
     "output_type": "error",
     "traceback": [
      "Error in knn(train.x, test.x, train.y, k = 5): 'train' and 'class' have different lengths\nTraceback:\n",
      "1. knn(train.x, test.x, train.y, k = 5)",
      "2. stop(\"'train' and 'class' have different lengths\")"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Question 4\n",
    "# -------------------------------\n",
    "#I dont know why this wouldnt run!? hopefully we'll clarify in class...\n",
    "\n",
    "# (a)\n",
    "library(tidyverse)\n",
    "install.packages(\"class\")\n",
    "library(class)\n",
    "\n",
    "\n",
    "data <- read_csv(\"hcp_data/unrestricted_trimmed_1_7_2020_10_50_44.csv\")%>%\n",
    "select(Subject, Gender, Flanker_Unadj)%>% filter(!is.na(Flanker_Unadj), !is.na(Gender))\n",
    "\n",
    "data <- data[1:1206,]\n",
    "\n",
    "test.id <- sample(nrow(data), 200)\n",
    "head(data)\n",
    "\n",
    "#identifying test values \n",
    "test.x = data[test.id, 3]\n",
    "test.y = data[test.id, 2]\n",
    "\n",
    "#pulling train data \n",
    "train.x = data[-test.id, 3]\n",
    "train.y = data[-test.id, 2]\n",
    "\n",
    "\n",
    "knn.pred <- knn(train.x, test.x, train.y, k=5 )\n",
    "table(knn.pred, test.y)\n",
    "mean(knn.pred == test.y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Now repeat your analysis using a range of k's, from 1-100. Plot the performance of the classifier (i.e., accuracy) for each value of k. Which value gives you the highest accuracy and what is the accuracy for that best k?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in knn(train.x, test.x, c1 = train.y, k = i): unused argument (c1 = train.y)\n",
     "output_type": "error",
     "traceback": [
      "Error in knn(train.x, test.x, c1 = train.y, k = i): unused argument (c1 = train.y)\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# (b)\n",
    "\n",
    "\n",
    "knn.pd <- rep(0, 100)\n",
    "for(i in 1:100){\n",
    "    knn.pd <- knn(train.x, test.x, c1 = train.y , k = i)\n",
    "    knn.acc[i] <- mean(knn.pd == test.y)\n",
    "}\n",
    "\n",
    "plot(1:100, knn.cc)\n",
    "\n",
    "which.max(knn.acc)\n",
    "\n",
    "\n",
    "#I tried!! is it because i updated r??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Use bootstrapping to estimate the confidence on the regression coefficients for a logistic regression model using Flanker_unadj scores to predict Gender. Use 5000 iterations off the bootstrap. Report whether any of the coefficients are statistically significant using the standard error estimates off of the bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsed with column specification:\n",
      "cols(\n",
      "  .default = col_double(),\n",
      "  Release = \u001b[31mcol_character()\u001b[39m,\n",
      "  Acquisition = \u001b[31mcol_character()\u001b[39m,\n",
      "  Gender = \u001b[31mcol_character()\u001b[39m,\n",
      "  Age = \u001b[31mcol_character()\u001b[39m,\n",
      "  PSQI_BedTime = \u001b[34mcol_time(format = \"\")\u001b[39m,\n",
      "  PSQI_GetUpTime = \u001b[34mcol_time(format = \"\")\u001b[39m,\n",
      "  NEORAW_01 = \u001b[31mcol_character()\u001b[39m,\n",
      "  NEORAW_02 = \u001b[31mcol_character()\u001b[39m,\n",
      "  NEORAW_03 = \u001b[31mcol_character()\u001b[39m,\n",
      "  NEORAW_04 = \u001b[31mcol_character()\u001b[39m,\n",
      "  NEORAW_05 = \u001b[31mcol_character()\u001b[39m,\n",
      "  NEORAW_06 = \u001b[31mcol_character()\u001b[39m,\n",
      "  NEORAW_07 = \u001b[31mcol_character()\u001b[39m,\n",
      "  NEORAW_08 = \u001b[31mcol_character()\u001b[39m,\n",
      "  NEORAW_09 = \u001b[31mcol_character()\u001b[39m,\n",
      "  NEORAW_10 = \u001b[31mcol_character()\u001b[39m,\n",
      "  NEORAW_11 = \u001b[31mcol_character()\u001b[39m,\n",
      "  NEORAW_12 = \u001b[31mcol_character()\u001b[39m,\n",
      "  NEORAW_13 = \u001b[31mcol_character()\u001b[39m,\n",
      "  NEORAW_14 = \u001b[31mcol_character()\u001b[39m\n",
      "  # ... with 46 more columns\n",
      ")\n",
      "\n",
      "See spec(...) for full column specifications.\n",
      "\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in statistic(data, original, ...): could not find function \"statistic\"\n",
     "output_type": "error",
     "traceback": [
      "Error in statistic(data, original, ...): could not find function \"statistic\"\nTraceback:\n",
      "1. boot(boot.fn, hcp, R = 5000)"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Question 5\n",
    "# -------------------------------\n",
    "\n",
    "#I cant get anything to run today!!! \n",
    "\n",
    "hcp <- read_csv(\"hcp_data/unrestricted_trimmed_1_7_2020_10_50_44.csv\")%>%\n",
    "select(Subject, Gender, Flanker_Unadj)%>% filter(!is.na(Flanker_Unadj), !is.na(Gender))\n",
    "\n",
    "library(boot)\n",
    "boot.fn <- function(d, index){\n",
    "    model <- glm(Gender ~ Flanker_Unadj, data=data, family = binomial, subset = index, data = d)\n",
    "}\n",
    "\n",
    "boot_obj <- boot(boot.fn, hcp, R = 5000)\n",
    "boot.out <- tidy(boot_obj,conf.int=TRUE,conf.method=\"perc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
